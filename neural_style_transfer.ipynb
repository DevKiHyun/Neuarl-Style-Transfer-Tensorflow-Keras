{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Style_Transfer_Keras&TF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJVvZknOr5EJ",
        "colab_type": "text"
      },
      "source": [
        "## Upload Content Image!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juZMtaJeKGWw",
        "colab_type": "code",
        "outputId": "544144ca-8876-4e22-fbe1-b625b4e087ac",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "\"\"\" Content Image \"\"\"\n",
        "print(\"Upload Content Image file! Please, file name is 'content_image.*'\" )\n",
        "\n",
        "content_list = files.upload()\n",
        "\n",
        "for fn in content_list.keys():\n",
        "  print('User uploaded \"Content Image\" File \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(content_list[fn])))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload Content Image file! Please, file name is 'content_image.*'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b07f433d-c6c9-4488-96f7-710fd0548f3f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b07f433d-c6c9-4488-96f7-710fd0548f3f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving blue-moon-lake.jpg to blue-moon-lake.jpg\n",
            "User uploaded \"Content Image\" File \"blue-moon-lake.jpg\" with length 102728 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mKwffUm8_T3",
        "colab_type": "code",
        "outputId": "d9ff3886-511b-4880-c3e3-dc1d7c1a3780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "content_image_name = list(content_list)[0]\n",
        "\n",
        "print(content_image_name)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blue-moon-lake.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQpUqnX8sAMw",
        "colab_type": "text"
      },
      "source": [
        "## Upload Sytle Image!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzCY-R5yKK6E",
        "colab_type": "code",
        "outputId": "a37aab00-5f88-4ab8-8510-d057f91eab2b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "\"\"\" Style Image \"\"\"\n",
        "print(\"Upload Style Image file! Please, file name is 'style_image.*'\")\n",
        "\n",
        "style_list = files.upload()\n",
        "\n",
        "for fn in style_list.keys():\n",
        "  print('User uploaded \"Style Image\" File \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(style_list[fn])))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload Style Image file! Please, file name is 'style_image.*'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7f1540e3-2aa0-41a4-ab4b-a0263a4f8ae2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7f1540e3-2aa0-41a4-ab4b-a0263a4f8ae2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving wave.jpg to wave.jpg\n",
            "User uploaded \"Style Image\" File \"wave.jpg\" with length 123262 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGh5Arq39MS3",
        "colab_type": "code",
        "outputId": "63ca6503-73f1-4c1d-8a72-1eaddf795220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "style_image_name = list(style_list)[0]\n",
        "\n",
        "print(style_image_name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wave.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k0Q68C9bYCZ",
        "colab_type": "text"
      },
      "source": [
        "## Custom argument!!!\n",
        "\n",
        "## Arguments that recommend customization. : loss_ratio, content_blocks,  tv_weight,  initial_type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GNZ3D6DGt1l",
        "colab_type": "code",
        "outputId": "023a1826-dabd-4a4b-a1e8-cd237d19320e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "\n",
        "\n",
        "def show_weights_histogram(model, name='block1_conv1'):\n",
        "    w = model.get_layer(name).get_weights()[0]\n",
        "    plt.hist(w.flatten())\n",
        "    plt.title(\"w values after 'imagenet' weights are loaded\")\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "def get_image_data(path, resize=None, dtype=np.float32):\n",
        "    filepath = glob.glob(path)[0]\n",
        "    image = cv2.imread(filepath).astype(dtype)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    print(\"Image Shape = \", image.shape)\n",
        "    \n",
        "    ratio = None\n",
        "    if resize != None:\n",
        "      if type(resize) == int:\n",
        "        height, width, n_channel = image.shape\n",
        "\n",
        "        min_size = width if height > width else height\n",
        "\n",
        "        ratio = resize / min_size\n",
        "        \n",
        "        resize = (int(width * ratio), int(height * ratio))\n",
        "\n",
        "      else:\n",
        "        assert type(resize) == tuple, \"If 'resize' is not 'int', then should be 'tuple' = (resize_width, resize_height)\"\n",
        "        \n",
        "        resize = (resize[1], resize[0])\n",
        "        \n",
        "      image = cv2.resize(image, resize, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "      \n",
        "    return image, ratio\n",
        "  \n",
        "  \n",
        "def preprocessing(image):\n",
        "    image[:, :, 0] -= 123.68\n",
        "    image[:, :, 1] -= 116.779\n",
        "    image[:, :, 2] -= 103.939\n",
        "    \n",
        "    return image\n",
        "  \n",
        "  \n",
        "def deprocessing(image):\n",
        "    image[:, :, 0] += 123.68\n",
        "    image[:, :, 1] += 116.779\n",
        "    image[:, :, 2] += 103.939\n",
        "    \n",
        "    image = np.clip(image, 0, 255).astype('uint8')\n",
        "    \n",
        "    return image\n",
        "  \n",
        "\n",
        "def Gram_Matrix(input_tensor):\n",
        "    # input_tensor Shape : (height, width, n_channel)\n",
        "    # We should reshape to (height * width, n_channel)\n",
        "    assert len(input_tensor.shape) == 3, \"'input_tensor' shape is wrong. 'input_tensor' should be shape : (height, width, n_channel)\"\n",
        "    \n",
        "    n_channel = input_tensor.shape[-1]\n",
        "    input_tensor = tf.reshape(input_tensor, shape=(-1, n_channel))\n",
        "    \n",
        "    # matmul(input.T, input)  ==> Gamma Matrix \n",
        "    gram_matrix = tf.matmul(tf.transpose(input_tensor), input_tensor)  # Shape : (n_channel, n_channel)\n",
        "\n",
        "    return gram_matrix\n",
        "\n",
        "  \n",
        "def total_variation_loss(x):\n",
        "    _, height, width, _ = x.shape\n",
        "    \n",
        "    height = height.value\n",
        "    width  = width.value\n",
        "  \n",
        "    a = tf.square(x[:, :height-1, :width-1, :] - x[:, 1:, :width-1, :])\n",
        "    b = tf.square(x[:, :height-1, :width-1, :] - x[:, :height-1, 1:, :])\n",
        "    \n",
        "    return tf.reduce_sum(tf.pow(a + b, 1.25))\n",
        "  \n",
        "  \n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--content_image_path', type=str, default='./images/content/content_image.*', \n",
        "                        help=\"Path to the content image. ex)'./images/content/content_image.jpg'\")\n",
        "    \n",
        "    parser.add_argument('--style_image_path', type=str, default='./images/style/style_image.*', \n",
        "                        help=\"Path to the style image. ex) './images/style/style_image.jpg'\")\n",
        "    \n",
        "    parser.add_argument('--model_type', type=int, default=0, \n",
        "                        help=\"Options are 0 == VGG16, 1 == VGG19.\")\n",
        "\n",
        "    parser.add_argument('--image_resize', type=int, default= 512, \n",
        "                        help=\"If image_resize == 'int', min(height, width) of images = image_resize.\\\n",
        "                              If image_resize == 'tuple',  (height, width) of images = image_resize.\")\n",
        "    \n",
        "    parser.add_argument('--rescale_image', type=bool, default= False, \n",
        "                        help=\"Rescale final image to original size.\")\n",
        "    \n",
        "    parser.add_argument('--content_blocks', type=str, default=['block4_conv2'],\n",
        "                        help=\"Layer list for feature vector of Content image.\")\n",
        "    \n",
        "    parser.add_argument('--style_blocks', type=str, default=['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1'],\n",
        "                        help='Layer list for feature vector of Style image.')\n",
        "    \n",
        "    parser.add_argument('--loss_ratio', type=float, default= 1e-3,\n",
        "                        help='alpha / beta for loss function.')\n",
        "    \n",
        "    parser.add_argument(\"--total_variation_weight\", type=float, default=0, \n",
        "                         help=\"Total Variation weight. Default : 8.5e-5\")\n",
        "    \n",
        "    parser.add_argument('--initial_type', type=str, default='random',\n",
        "                        help=\"Options are 'content', 'style', 'random'.\")\n",
        "    \n",
        "    parser.add_argument('--optimizer_type', type=int, default=1,\n",
        "                        help='Options are 0 == Adam Optimizer, 1 == L-BFGS-B Optimizer.')\n",
        "    \n",
        "    parser.add_argument('--learning_rate', type=float, default=1e+1, help='-')\n",
        "    \n",
        "    parser.add_argument('--beta_1', type=float, default=0.9, help='-')\n",
        "    \n",
        "    parser.add_argument('--beta_2', type=float, default=0.999, help='-')\n",
        "    \n",
        "    parser.add_argument('--epsilon', type=float, default=1e-08, help='-')\n",
        "    \n",
        "    parser.add_argument('--iteration', type=int, default=150, help='-')\n",
        "\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    \n",
        "    \"\"\" HYPER PARAMETER  \"\"\"\n",
        "    content_img_path    = content_image_name  # args.content_image_path\n",
        "    style_img_path      = style_image_name  # args.style_image_path\n",
        "    image_resize        = args.image_resize\n",
        "    rescale_image       = args.rescale_image\n",
        "    content_blocks      = args.content_blocks\n",
        "    style_blocks        = args.style_blocks\n",
        "    style_weights       = {block : 1/len(style_blocks) for block in style_blocks}  # The factor 'w' was always equal to one divided by the number of active layers in the paper\n",
        "    loss_ratio          = args.loss_ratio  # alpha / beta\n",
        "    tv_weight           = args.total_variation_weight\n",
        "    initial_type        = args.initial_type\n",
        "    model_type          = args.model_type\n",
        "    optimizer_type      = args.optimizer_type\n",
        "    learning_rate       = args.learning_rate\n",
        "    beta_1              = args.beta_1\n",
        "    beta_2              = args.beta_2\n",
        "    epsilon             = args.epsilon\n",
        "    iteration           = args.iteration\n",
        "\n",
        "    \n",
        "    \"\"\" Content, Style, Generated Image \"\"\"\n",
        "    # generated_image is trainable parameter. Initialize by random_normal noise.\n",
        "    content_image, rescale = get_image_data(content_img_path, image_resize)\n",
        "    style_image, _         = get_image_data(style_img_path, content_image.shape[:2])\n",
        "    \n",
        "    print(\"After Image Shape\", content_image.shape)\n",
        "    \n",
        "    if initial_type == 'content':\n",
        "      generated_image = content_image.copy()\n",
        "    elif initial_type == 'style':\n",
        "      generated_image = style_image.copy()\n",
        "    elif initial_type == 'random':\n",
        "      generated_image = tf.random_normal(shape=content_image.shape, stddev=np.std(content_image))\n",
        "    \n",
        "    generated_image = tf.Variable(generated_image, dtype=tf.float32, name='random_noise', trainable=True)\n",
        "\n",
        "\n",
        "    # preprocessing - subtract mean rgb value of 'imagenet'\n",
        "    content_image = preprocessing(content_image)\n",
        "    style_image   = preprocessing(style_image)\n",
        "\n",
        "    \n",
        "    # Reshape to 1 batch image and convert to Tensor.\n",
        "    image_shape = (1,) + content_image.shape  # shape = (1, height, width, 3)\n",
        "    \n",
        "    content_image   = content_image.reshape(image_shape)\n",
        "    style_image     = style_image.reshape(image_shape)\n",
        "    init_tensor    = tf.reshape(generated_image, shape=image_shape)\n",
        "\n",
        "\n",
        "    # Load pretrained model using Keras API\n",
        "    with tf.variable_scope('pretrained_model'):\n",
        "      if model_type == 0:\n",
        "        model = VGG16(weights='imagenet', input_tensor=init_tensor, include_top=False)\n",
        "      elif model_type == 1:\n",
        "        model = VGG19(weights='imagenet', input_tensor=init_tensor, include_top=False)\n",
        "        \n",
        "      keras_variables = [var.name for var in tf.global_variables() if 'pretrained_model' in var.name]\n",
        "    \n",
        "    # Output Tensor of Keras model into Dictionary\n",
        "    output_dict = {layer.name: layer.output for layer in model.layers}\n",
        "        \n",
        "\n",
        "    # Session\n",
        "    sess = K.get_session() \n",
        "    K.set_session(sess)\n",
        "      \n",
        "      \n",
        "    # Get Content feature and Style feature\n",
        "    Ps = {}\n",
        "    As = {}\n",
        "    \n",
        "    for block in content_blocks:\n",
        "      feature_vectors = sess.run(output_dict[block], feed_dict={init_tensor : content_image})[0]\n",
        "      Ps[block] = tf.constant(feature_vectors, dtype=tf.float32)  # feature vector of Content image\n",
        "      \n",
        "    for block in style_blocks:\n",
        "      feature_vectors = sess.run(output_dict[block], feed_dict={init_tensor : style_image})[0]\n",
        "      As[block] = Gram_Matrix(feature_vectors)   # Gram Matrix of Style feature vector\n",
        "\n",
        "      \n",
        "    \"\"\" \n",
        "    Loss  \n",
        "    = alpha * content_loss + beta * style_loss (alpha/beta = loss_ratio)\n",
        "    \n",
        "    my code)\n",
        "    loss = loss_ratio * content_loss + style_loss\n",
        "    \"\"\"\n",
        "    \n",
        "    # Content Loss\n",
        "    content_loss = 0\n",
        "    for block in content_blocks:\n",
        "      F = output_dict[block][0] # feature vector of Generated iamge\n",
        "      P = Ps[block]             # feature vector of Content image\n",
        "\n",
        "      content_loss +=  1/2 * tf.reduce_sum(tf.pow((F - P), 2))\n",
        "\n",
        "      \n",
        "    # Style Loss \n",
        "    style_loss = 0\n",
        "    for block in style_blocks:\n",
        "      F = output_dict[block][0]            \n",
        "      A = As[block]                        # Gram Matrix of Style feature vector\n",
        "      G = Gram_Matrix(F)                   # Gram Matrix of Generated feature vector\n",
        "      \n",
        "      height, width, n_channel = F.shape\n",
        "      size = height.value * width.value\n",
        "      scale = 1 / (4 * (n_channel.value ** 2) * (size ** 2))\n",
        "      w = style_weights[block]\n",
        "      \n",
        "      style_loss += w * scale * tf.reduce_sum(tf.pow((G - A), 2))\n",
        "      \n",
        "    # Total Variation Loss\n",
        "    tv_loss = tv_weight * total_variation_loss(init_tensor)\n",
        "      \n",
        "    loss = loss_ratio * content_loss + style_loss + tv_loss\n",
        "\n",
        "\n",
        "    # Minimize cost\n",
        "    trainble_variables = [var for var in tf.global_variables() if 'pretrained_model' not in var.name]  # Should not train the weights of pretrained model.\n",
        "    if optimizer_type == 0:\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta_1, beta2=beta_2, epsilon=epsilon).minimize(loss, var_list=trainble_variables)\n",
        "    elif optimizer_type == 1:\n",
        "        optimizer = tf.contrib.opt.ScipyOptimizerInterface(loss, var_list=trainble_variables, method='L-BFGS-B', options={'maxiter': iteration})\n",
        "\n",
        "\n",
        "    # Initialize\n",
        "    uninitialize_variables = [var for var in tf.global_variables() if var.name not in keras_variables]\n",
        "    sess.run(tf.variables_initializer(uninitialize_variables))\n",
        "\n",
        "    \n",
        "    # Make sure that pretrained model's weights are initialized. They should never be initialized.\n",
        "    #show_weights_histogram(model)\n",
        "    \n",
        "    \n",
        "    # Training\n",
        "    with sess.as_default():\n",
        "      \n",
        "      if optimizer_type == 0:  # Adam Optimizer\n",
        "        for i in range(iteration):  \n",
        "            _cost, _c_cost, _s_cost, _tv_cost, _ = sess.run([loss, content_loss, style_loss, tv_loss, optimizer])\n",
        "\n",
        "            if i % ((iteration // 10)) == 0:\n",
        "                print('iter : {}'.format(i + 1), 'total loss : {:.2f}'.format(_cost),\n",
        "                      'content_loss : {:.2f}'.format(_c_cost), 'style_loss : {:.2f}'.format(_s_cost))\n",
        "                \n",
        "      if optimizer_type == 1:  # L-BFGS-B Optimizer \n",
        "        _iter = 0\n",
        "        def callback(_cost, _c_cost, _s_cost, _tv_loss):\n",
        "            global _iter\n",
        "\n",
        "            if _iter % ((iteration // 10)) == 0:\n",
        "              print('iter : {}'.format(_iter + 1), 'total loss : {:.2f}'.format(_cost),\n",
        "                    'content_loss : {:.2f}'.format(_c_cost), 'style_loss : {:.2f}'.format(_s_cost),\n",
        "                     'tv_loss : {:.2f}'.format(_tv_loss))\n",
        "\n",
        "            _iter += 1\n",
        "\n",
        "        optimizer.minimize(sess, fetches=[loss, content_loss, style_loss, tv_loss], loss_callback=callback)\n",
        "        \n",
        "      \n",
        "    print(\"Complete Sytle Transfer!\")\n",
        "    \n",
        "    generated_image = sess.run(init_tensor)[0]\n",
        "\n",
        "    # deprocessing - add mean rgb value of 'imagenet'\n",
        "    generated_image = deprocessing(generated_image)\n",
        "    \n",
        "    if rescale_image == True:\n",
        "      generated_image = cv2.resize(generated_image, None, fx=1/rescale, fy=1/rescale, interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    print(\"Final Image Shape =\", generated_image.shape)\n",
        "    \n",
        "    K.clear_session()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Shape =  (1200, 1920, 3)\n",
            "Image Shape =  (514, 928, 3)\n",
            "After Image Shape (512, 819, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "iter : 1 total loss : 1077892736.00 content_loss : 61425934336.00 style_loss : 1047179776.00 tv_loss : 0.00\n",
            "iter : 16 total loss : 98557280.00 content_loss : 70415360000.00 style_loss : 63349596.00 tv_loss : 0.00\n",
            "iter : 31 total loss : 38365852.00 content_loss : 49890021376.00 style_loss : 13420839.00 tv_loss : 0.00\n",
            "iter : 46 total loss : 27719788.00 content_loss : 38755540992.00 style_loss : 8342017.00 tv_loss : 0.00\n",
            "iter : 61 total loss : 23132380.00 content_loss : 33337579520.00 style_loss : 6463588.00 tv_loss : 0.00\n",
            "iter : 76 total loss : 20353764.00 content_loss : 29787299840.00 style_loss : 5460113.00 tv_loss : 0.00\n",
            "iter : 91 total loss : 18752004.00 content_loss : 27700322304.00 style_loss : 4901841.00 tv_loss : 0.00\n",
            "iter : 106 total loss : 17682732.00 content_loss : 26246098944.00 style_loss : 4559681.50 tv_loss : 0.00\n",
            "iter : 121 total loss : 16909558.00 content_loss : 25176891392.00 style_loss : 4321112.00 tv_loss : 0.00\n",
            "iter : 136 total loss : 16317444.00 content_loss : 24362016768.00 style_loss : 4136434.50 tv_loss : 0.00\n",
            "iter : 151 total loss : 15853626.00 content_loss : 23689420800.00 style_loss : 4008915.25 tv_loss : 0.00\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 15700236.000000\n",
            "  Number of iterations: 150\n",
            "  Number of functions evaluations: 157\n",
            "Complete Sytle Transfer!\n",
            "Final Image Shape = (512, 819, 3)\n",
            "Final Image name = blue_moon_lake_wave\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duKRrRGloYbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save image.\n",
        "\n",
        "save_name = content_image_name[:-4].replace('-','_') + '_' + style_image_name[:-4].replace('-','_')\n",
        "print('Final Image name =', save_name)\n",
        "\n",
        "cv2.imwrite('./images/sample/{}.jpg'.format(save_name), cv2.cvtColor(generated_image, cv2.COLOR_RGB2BGR))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJJ_lc7Rtch5",
        "colab_type": "text"
      },
      "source": [
        "## Download Image!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Og88dgtf8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('{}.jpg'.format(save_name))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
