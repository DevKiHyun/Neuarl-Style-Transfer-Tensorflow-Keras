{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_style_transfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevKiHyun/Neural-Style-Transfer-Tensorflow-Keras/blob/master/neural_style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJVvZknOr5EJ",
        "colab_type": "text"
      },
      "source": [
        "## Upload Content Image!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juZMtaJeKGWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "\"\"\" Content Image \"\"\"\n",
        "print(\"Upload Content Image file! Please, file name is 'content_image.*'\" )\n",
        "\n",
        "content_list = files.upload()\n",
        "\n",
        "for fn in content_list.keys():\n",
        "  print('User uploaded \"Content Image\" File \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(content_list[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mKwffUm8_T3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_image_name = list(content_list)[0]\n",
        "\n",
        "print(content_image_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQpUqnX8sAMw",
        "colab_type": "text"
      },
      "source": [
        "## Upload Style Image!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzCY-R5yKK6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Style Image \"\"\"\n",
        "print(\"Upload Style Image file! Please, file name is 'style_image.*'\")\n",
        "\n",
        "style_list = files.upload()\n",
        "\n",
        "for fn in style_list.keys():\n",
        "  print('User uploaded \"Style Image\" File \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(style_list[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGh5Arq39MS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_image_name = list(style_list)[0]\n",
        "\n",
        "print(style_image_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k0Q68C9bYCZ",
        "colab_type": "text"
      },
      "source": [
        "## Custom argument!!!\n",
        "\n",
        "## Arguments that recommend customization. : loss_ratio, content_blocks,  tv_weight,  initial_type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GNZ3D6DGt1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "\n",
        "\n",
        "def show_weights_histogram(model, name='block1_conv1'):\n",
        "    w = model.get_layer(name).get_weights()[0]\n",
        "    plt.hist(w.flatten())\n",
        "    plt.title(\"w values after 'imagenet' weights are loaded\")\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "def get_image_data(path, resize=None, dtype=np.float32):\n",
        "    filepath = glob.glob(path)[0]\n",
        "    image = cv2.imread(filepath).astype(dtype)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    print(\"Image Shape = \", image.shape)\n",
        "    \n",
        "    ratio = None\n",
        "    if resize != None:\n",
        "      if type(resize) == int:\n",
        "        height, width, n_channel = image.shape\n",
        "\n",
        "        min_size = width if height > width else height\n",
        "\n",
        "        ratio = resize / min_size\n",
        "        \n",
        "        resize = (int(width * ratio), int(height * ratio))\n",
        "\n",
        "      else:\n",
        "        assert type(resize) == tuple, \"If 'resize' is not 'int', then should be 'tuple' = (resize_width, resize_height)\"\n",
        "        \n",
        "        resize = (resize[1], resize[0])\n",
        "        \n",
        "      image = cv2.resize(image, resize, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "      \n",
        "    return image, ratio\n",
        "  \n",
        "  \n",
        "def preprocessing(image):\n",
        "    image[:, :, 0] -= 123.68\n",
        "    image[:, :, 1] -= 116.779\n",
        "    image[:, :, 2] -= 103.939\n",
        "    \n",
        "    return image\n",
        "  \n",
        "  \n",
        "def deprocessing(image):\n",
        "    image[:, :, 0] += 123.68\n",
        "    image[:, :, 1] += 116.779\n",
        "    image[:, :, 2] += 103.939\n",
        "    \n",
        "    image = np.clip(image, 0, 255).astype('uint8')\n",
        "    \n",
        "    return image\n",
        "  \n",
        "\n",
        "def Gram_Matrix(input_tensor):\n",
        "    # input_tensor Shape : (height, width, n_channel)\n",
        "    # We should reshape to (height * width, n_channel)\n",
        "    assert len(input_tensor.shape) == 3, \"'input_tensor' shape is wrong. 'input_tensor' should be shape : (height, width, n_channel)\"\n",
        "    \n",
        "    n_channel = input_tensor.shape[-1]\n",
        "    input_tensor = tf.reshape(input_tensor, shape=(-1, n_channel))\n",
        "    \n",
        "    # matmul(input.T, input)  ==> Gamma Matrix \n",
        "    gram_matrix = tf.matmul(tf.transpose(input_tensor), input_tensor)  # Shape : (n_channel, n_channel)\n",
        "\n",
        "    return gram_matrix\n",
        "\n",
        "  \n",
        "def total_variation_loss(x):\n",
        "    _, height, width, _ = x.shape\n",
        "    \n",
        "    height = height.value\n",
        "    width  = width.value\n",
        "  \n",
        "    a = tf.square(x[:, :height-1, :width-1, :] - x[:, 1:, :width-1, :])\n",
        "    b = tf.square(x[:, :height-1, :width-1, :] - x[:, :height-1, 1:, :])\n",
        "    \n",
        "    return tf.reduce_sum(tf.pow(a + b, 1.25))\n",
        "  \n",
        "  \n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--content_image_path', type=str, default='./images/content/content_image.*', \n",
        "                        help=\"Path to the content image. ex)'./images/content/content_image.jpg'\")\n",
        "    \n",
        "    parser.add_argument('--style_image_path', type=str, default='./images/style/style_image.*', \n",
        "                        help=\"Path to the style image. ex) './images/style/style_image.jpg'\")\n",
        "    \n",
        "    parser.add_argument('--model_type', type=int, default=0, \n",
        "                        help=\"Options are 0 == VGG16, 1 == VGG19.\")\n",
        "\n",
        "    parser.add_argument('--image_resize', type=int, default= 512, \n",
        "                        help=\"If image_resize == 'int', min(height, width) of images = image_resize.\\\n",
        "                              If image_resize == 'tuple',  (height, width) of images = image_resize.\")\n",
        "    \n",
        "    parser.add_argument('--rescale_image', type=bool, default= False, \n",
        "                        help=\"Rescale final image to original size.\")\n",
        "    \n",
        "    parser.add_argument('--content_blocks', type=str, default=['block4_conv2'],\n",
        "                        help=\"Layer list for feature vector of Content image.\")\n",
        "    \n",
        "    parser.add_argument('--style_blocks', type=str, default=['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1'],\n",
        "                        help='Layer list for feature vector of Style image.')\n",
        "    \n",
        "    parser.add_argument('--loss_ratio', type=float, default= 1e-3,\n",
        "                        help='alpha / beta for loss function.')\n",
        "    \n",
        "    parser.add_argument(\"--total_variation_weight\", type=float, default=0, \n",
        "                         help=\"Total Variation weight. Default : 8.5e-5\")\n",
        "    \n",
        "    parser.add_argument('--initial_type', type=str, default='random',\n",
        "                        help=\"Options are 'content', 'style', 'random'.\")\n",
        "    \n",
        "    parser.add_argument('--optimizer_type', type=int, default=1,\n",
        "                        help='Options are 0 == Adam Optimizer, 1 == L-BFGS-B Optimizer.')\n",
        "    \n",
        "    parser.add_argument('--learning_rate', type=float, default=1e+1, help='-')\n",
        "    \n",
        "    parser.add_argument('--beta_1', type=float, default=0.9, help='-')\n",
        "    \n",
        "    parser.add_argument('--beta_2', type=float, default=0.999, help='-')\n",
        "    \n",
        "    parser.add_argument('--epsilon', type=float, default=1e-08, help='-')\n",
        "    \n",
        "    parser.add_argument('--iteration', type=int, default=150, help='-')\n",
        "\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    \n",
        "    \"\"\" HYPER PARAMETER  \"\"\"\n",
        "    content_img_path    = content_image_name  # args.content_image_path\n",
        "    style_img_path      = style_image_name  # args.style_image_path\n",
        "    image_resize        = args.image_resize\n",
        "    rescale_image       = args.rescale_image\n",
        "    content_blocks      = args.content_blocks\n",
        "    style_blocks        = args.style_blocks\n",
        "    style_weights       = {block : 1/len(style_blocks) for block in style_blocks}  # The factor 'w' was always equal to one divided by the number of active layers in the paper\n",
        "    loss_ratio          = args.loss_ratio  # alpha / beta\n",
        "    tv_weight           = args.total_variation_weight\n",
        "    initial_type        = args.initial_type\n",
        "    model_type          = args.model_type\n",
        "    optimizer_type      = args.optimizer_type\n",
        "    learning_rate       = args.learning_rate\n",
        "    beta_1              = args.beta_1\n",
        "    beta_2              = args.beta_2\n",
        "    epsilon             = args.epsilon\n",
        "    iteration           = args.iteration\n",
        "\n",
        "    \n",
        "    \"\"\" Content, Style, Generated Image \"\"\"\n",
        "    # generated_image is trainable parameter. Initialize by random_normal noise.\n",
        "    content_image, rescale = get_image_data(content_img_path, image_resize)\n",
        "    style_image, _         = get_image_data(style_img_path, content_image.shape[:2])\n",
        "    \n",
        "    print(\"After Image Shape\", content_image.shape)\n",
        "    \n",
        "    if initial_type == 'content':\n",
        "      generated_image = content_image.copy()\n",
        "    elif initial_type == 'style':\n",
        "      generated_image = style_image.copy()\n",
        "    elif initial_type == 'random':\n",
        "      generated_image = tf.random_normal(shape=content_image.shape, stddev=np.std(content_image))\n",
        "    \n",
        "    generated_image = tf.Variable(generated_image, dtype=tf.float32, name='random_noise', trainable=True)\n",
        "\n",
        "\n",
        "    # preprocessing - subtract mean rgb value of 'imagenet'\n",
        "    content_image = preprocessing(content_image)\n",
        "    style_image   = preprocessing(style_image)\n",
        "\n",
        "    \n",
        "    # Reshape to 1 batch image and convert to Tensor.\n",
        "    image_shape = (1,) + content_image.shape  # shape = (1, height, width, 3)\n",
        "    \n",
        "    content_image   = content_image.reshape(image_shape)\n",
        "    style_image     = style_image.reshape(image_shape)\n",
        "    init_tensor    = tf.reshape(generated_image, shape=image_shape)\n",
        "\n",
        "\n",
        "    # Load pretrained model using Keras API\n",
        "    with tf.variable_scope('pretrained_model'):\n",
        "      if model_type == 0:\n",
        "        model = VGG16(weights='imagenet', input_tensor=init_tensor, include_top=False)\n",
        "      elif model_type == 1:\n",
        "        model = VGG19(weights='imagenet', input_tensor=init_tensor, include_top=False)\n",
        "        \n",
        "      keras_variables = [var.name for var in tf.global_variables() if 'pretrained_model' in var.name]\n",
        "    \n",
        "    # Output Tensor of Keras model into Dictionary\n",
        "    output_dict = {layer.name: layer.output for layer in model.layers}\n",
        "        \n",
        "\n",
        "    # Session\n",
        "    sess = K.get_session() \n",
        "    K.set_session(sess)\n",
        "      \n",
        "      \n",
        "    # Get Content feature and Style feature\n",
        "    Ps = {}\n",
        "    As = {}\n",
        "    \n",
        "    for block in content_blocks:\n",
        "      feature_vectors = sess.run(output_dict[block], feed_dict={init_tensor : content_image})[0]\n",
        "      Ps[block] = tf.constant(feature_vectors, dtype=tf.float32)  # feature vector of Content image\n",
        "      \n",
        "    for block in style_blocks:\n",
        "      feature_vectors = sess.run(output_dict[block], feed_dict={init_tensor : style_image})[0]\n",
        "      As[block] = Gram_Matrix(feature_vectors)   # Gram Matrix of Style feature vector\n",
        "\n",
        "      \n",
        "    \"\"\" \n",
        "    Loss  \n",
        "    = alpha * content_loss + beta * style_loss (alpha/beta = loss_ratio)\n",
        "    \n",
        "    my code)\n",
        "    loss = loss_ratio * content_loss + style_loss\n",
        "    \"\"\"\n",
        "    \n",
        "    # Content Loss\n",
        "    content_loss = 0\n",
        "    for block in content_blocks:\n",
        "      F = output_dict[block][0] # feature vector of Generated iamge\n",
        "      P = Ps[block]             # feature vector of Content image\n",
        "\n",
        "      content_loss +=  1/2 * tf.reduce_sum(tf.pow((F - P), 2))\n",
        "\n",
        "      \n",
        "    # Style Loss \n",
        "    style_loss = 0\n",
        "    for block in style_blocks:\n",
        "      F = output_dict[block][0]            \n",
        "      A = As[block]                        # Gram Matrix of Style feature vector\n",
        "      G = Gram_Matrix(F)                   # Gram Matrix of Generated feature vector\n",
        "      \n",
        "      height, width, n_channel = F.shape\n",
        "      size = height.value * width.value\n",
        "      scale = 1 / (4 * (n_channel.value ** 2) * (size ** 2))\n",
        "      w = style_weights[block]\n",
        "      \n",
        "      style_loss += w * scale * tf.reduce_sum(tf.pow((G - A), 2))\n",
        "      \n",
        "    # Total Variation Loss\n",
        "    tv_loss = tv_weight * total_variation_loss(init_tensor)\n",
        "      \n",
        "    loss = loss_ratio * content_loss + style_loss + tv_loss\n",
        "\n",
        "\n",
        "    # Minimize cost\n",
        "    trainble_variables = [var for var in tf.global_variables() if 'pretrained_model' not in var.name]  # Should not train the weights of pretrained model.\n",
        "    if optimizer_type == 0:\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta_1, beta2=beta_2, epsilon=epsilon).minimize(loss, var_list=trainble_variables)\n",
        "    elif optimizer_type == 1:\n",
        "        optimizer = tf.contrib.opt.ScipyOptimizerInterface(loss, var_list=trainble_variables, method='L-BFGS-B', options={'maxiter': iteration})\n",
        "\n",
        "\n",
        "    # Initialize\n",
        "    uninitialize_variables = [var for var in tf.global_variables() if var.name not in keras_variables]\n",
        "    sess.run(tf.variables_initializer(uninitialize_variables))\n",
        "\n",
        "    \n",
        "    # Make sure that pretrained model's weights are initialized. They should never be initialized.\n",
        "    #show_weights_histogram(model)\n",
        "    \n",
        "    \n",
        "    # Training\n",
        "    with sess.as_default():\n",
        "      \n",
        "      if optimizer_type == 0:  # Adam Optimizer\n",
        "        for i in range(iteration):  \n",
        "            _cost, _c_cost, _s_cost, _tv_cost, _ = sess.run([loss, content_loss, style_loss, tv_loss, optimizer])\n",
        "\n",
        "            if i % ((iteration // 10)) == 0:\n",
        "                print('iter : {}'.format(i + 1), 'total loss : {:.2f}'.format(_cost),\n",
        "                      'content_loss : {:.2f}'.format(_c_cost), 'style_loss : {:.2f}'.format(_s_cost))\n",
        "                \n",
        "      if optimizer_type == 1:  # L-BFGS-B Optimizer \n",
        "        _iter = 0\n",
        "        def callback(_cost, _c_cost, _s_cost, _tv_loss):\n",
        "            global _iter\n",
        "\n",
        "            if _iter % ((iteration // 10)) == 0:\n",
        "              print('iter : {}'.format(_iter + 1), 'total loss : {:.2f}'.format(_cost),\n",
        "                    'content_loss : {:.2f}'.format(_c_cost), 'style_loss : {:.2f}'.format(_s_cost),\n",
        "                     'tv_loss : {:.2f}'.format(_tv_loss))\n",
        "\n",
        "            _iter += 1\n",
        "\n",
        "        optimizer.minimize(sess, fetches=[loss, content_loss, style_loss, tv_loss], loss_callback=callback)\n",
        "        \n",
        "      \n",
        "    print(\"Complete Style Transfer!\")\n",
        "    \n",
        "    generated_image = sess.run(init_tensor)[0]\n",
        "\n",
        "    # deprocessing - add mean rgb value of 'imagenet'\n",
        "    generated_image = deprocessing(generated_image)\n",
        "    \n",
        "    if rescale_image == True:\n",
        "      generated_image = cv2.resize(generated_image, None, fx=1/rescale, fy=1/rescale, interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    print(\"Final Image Shape =\", generated_image.shape)\n",
        "    \n",
        "    K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duKRrRGloYbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save image.\n",
        "\n",
        "save_name = content_image_name[:-4].replace('-','_') + '_' + style_image_name[:-4].replace('-','_')\n",
        "print('Final Image name =', save_name)\n",
        "\n",
        "cv2.imwrite('{}.jpg'.format(save_name), cv2.cvtColor(generated_image, cv2.COLOR_RGB2BGR))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJJ_lc7Rtch5",
        "colab_type": "text"
      },
      "source": [
        "## Download Image!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Og88dgtf8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('{}.jpg'.format(save_name))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}